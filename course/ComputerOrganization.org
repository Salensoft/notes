* chap7
** introduction
   + principle of locality ::
     + programs access a relatively small portion of their address space at any
       instant of time.
   + temporal locality (locality in time) ::
     + If an item is referenced, it will tend to be referenced again soon
   + spatial locality (locality in space) ::
     + If an item is referenced, items whose addresses are close by will tend to be
       referenced soon.
   + memory hierarchy ::
     + main memory is implemented from DRAM, caches use SRAM, largest and slowest
       level uses magnetic disk.
   + miss rate ::
     + the fraction of memory accesses not found in a level of the momory
       hierarchy
   + hit time ::
     + the time required to access a level of the memory hierarchy, including the time
       needed to determine whether the access is a hit or a mass
   + miss penalty ::
     + the time required to fetch a block into a level of the memory hierarchy from the lower
       including the time to access the block, transmit it from one level to the other,
       and insert it in the level that experienced the miss
** basics of caches
   + tag ::
     + a fieldin a table used for a memory hierarchy that contains the adress information
       required to identify whether the associated block in the hierarchy corresponds
       to a requested word.
   + valid bit
   + larger block size, the miss rate decrease but the miss penalty increase
   + steps to be taken on an instruction cache miss
     1. send the original PC value (current PC - 4) to the memory
     2. instruct main memory to perform a read wait for the memory to complete its access
     3. write the cache entry, putting the data from the memory in the data portion of the
        entry, writing the upper bits of the address into the tag field, and turning
        the valid bit on
     4. restart the instruction execution at the first step, which will refetch the instruction
        this time finding it in the cache

   + write-through ::
     + always write the data into both the memory and the cache.
     + write miss ::
       + first fetch the words of the block from memory. After block is fetched and placed into
         the cache, we can overwrite the word that caused the miss into the cache block, we
         can also write the word to main memory using the full address.
       +
     + write buffer ::
       + stores the data while it's waiting to be written to memory, after writing the data
         into the cache and into the write buffer, the processor can continue execution.
         When a write to main memory completes, the entry in the write buffer is freed
   + write-back ::
     + when a write occurs, the new value is written only to the block in the cache.
       the modified block is written to the lower level of the hierarchy when it's replaced.
     + write a block
** measuring and improving cache performance
   + CPU time = (CPU execution clock cycles + Memory-stall clock cycles) *
                Clock cycle time
   + Memory-stall clock cycles = Read-stall cycles + Write-stall cycles
   + Read-stall cycles = Reads / Program * Read miss rate * Read miss penalty
   + Write-stall cycles = Writes / Program * Write miss rate * Write miss penalty +
                          Write buffer stalls
   + If write buffer stalls are negligible
     Memory-stall clock cycles = Memory accesses / Program * Miss rate * Miss penalty
   + fuly associative ::
     + a block in memory may be associated with any entry in the cache
     + to find a given block in a fully associative cache, all the entries in the cache
       must be searched
   + set asscociative ::
     + n-way set-associative cache
     + block may be placed in any element of the set, all the tags of all the elements of their
       set must be searched.
   + least recently used(LRU) ::
** virtual memory
   + page :: virtual memory block
   + page fault :: virtual memory miss
   + virtual address ::
     + an address that corresponds to a location in virtual space and is translated by address
       mapping to a physical address when memory is accessed
   + relocation ::
     + relocation maps the virtual addresses used by a program to different physical
       addresses before the addresses are used to access memory.
   + key decisions ::
     + pages should be large enough to try to amortize the high access time.
     + organizations that reduce page fault rate are attractive. Fully associative
       placement of pages in memory
     + page faults can be handled in software because the overhead will be small compared
       to the disk acess time. Use algorithm for choosing how to place pages.
     + write-through won't work since writes take too long
   + locate pages by using a table that indexes the memory, called *page table*. Indexed
     with the page number from the virtual address to discover the corresponding physical
     page number.
     Each program has its own page table.
   + page table register :: points to the start of the page table, physical address.
   + Because we don't know ahead of time when a page in memory will be chosen to be replaced,
     the operating system usually creates the space on disk for all the pages of a process when
     it creates the process. This is called *swap space*
   + reference bit \ use bit ::
     + a field that is set whenever a page is accessed and that is used to implement LRU or other
       replacement schemes.
     +

* MIAOMIAOMIAO
7.45
7.41 TLB
虚拟存储 page table的映射 给虚拟table算物理地址

多周期指令扩展

浮点运算、浮点表示
MIPS指令寻址方式
Cache\cache替换，cache资源计算，cache写回策略
全关联
虚拟存储，页缺失，页替换，虚拟地址->物理地址计算
C代码转换为汇编代码
多周期CPU：指令扩展，FSM（有限状态机）
算带宽
LB指令
** DMA(direct memory access)、中断、Polling优势、什么时候用、实时性
   polling浪费很多CPU时间
   interrupt have extra instruction to execute
   DMA doesn't need the control of precossor, won't consume CPU time
**
RAID 0-5
small read（一个盘 RAID3最小带宽） large read（所有盘 RAID345带宽一样）
掌握中断如何处理
