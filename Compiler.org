#+TITLE: Compiler
#+AUTHOR: wugouzi
#+LATEX_HEADER: \usepackage{tikz,qtree}
#+LATEX_HEADER: \usepackage{forest,syntax}
#+LATEX_HEADER: \input{preamble.tex}
#+LATEX_CLASS: article
#+EXPORT_FILE_NAME: latex/Compiler/Compiler.tex
#+LATEX_HEADER: \graphicspath{{../../images/Compiler/}}

* Chap1 introduction
  source code -> scanner -> [tokens] -> parser -> [syntax tree] -> semantic
  analyzer -> [annotated tree] -> source code optimizer -> [intermediate code]
  -> code generator -> [target code] -> target code optimizer -> [target code]

* chap2 scanning
  source code(*character stream*) -> *token stream*. Use regular expression.
  a ε R|S RS R* R+=R(R*) R?=(R|ε) [abce]=(a|b|c|e) [a-z] [^az]=anything but
  one of the listed chars

  comment "/*"([^*/]|[^*]"/"|"*"[^/])*"*/"


  finite automata

  Thompson's construction


  Minimizing the number of states in a DFA
  1. it begins with the most optimistic assumptions possible: it create two sets
     * one consisting of all the accepting states
     * the other consisting of all the nonaccepting states
  2. given this partition of the states of the original DFA, consider the
     transitions on *each character* a of the alphabet
     * if all accepting states have transitions on a to accepting states,
       defines an a-transition from the new accepting state to itself
     * if all accepting states have transitions on a to nonaccepting states ...
  3. given this partition of the states of the original DFA, consider the
     transitions on each character a of the alphabet
     * if there are two accepting states s and t that have transitions on a that
       land in different sets, no a-transition can be defined for this grouping
       of the states. a distinguish the states s and t
     * if there are two accpeting states s and t s.t. s has an a-transition to
       another accepting state, while t has no a-transition at all. a
       distinguish s and t

* Chap3 context-free grammars and parsing
** context-free grammars
   A context-free grammar involves recursion rules. 4-tuple $(V,\Sigma,S,\to)$.
   V nonterminal. Σ terminal. S start symbol. $\to\subset
   V\times(V\cup\Sigma)*$

   *Left recursive*: the nonterminal A appears as the first symbol on the
   right-hand side of the rule defining A

   *Right recusive*:

   *ε-production*: empty->ε
   A grammar that generates a language containing the empty string must have at
   least one *ε-production*
** Parse tree and abstract syntax trees
*** parse tree
    A *parse tree* corresponding to a derivation is a labeled tree
      * the interior nodes are labeled by *nonterminals*
      * the leaf is *terminals*

    *left-most derivation*
*** abstract symtax tree
    \begin{forest}
    [+ [3] [4] ]
    \end{forest}
** Ambiguity
*** ambiguity grammars
   *ambiguous grammar*: a grammar that generates a string with two distinct parse
   trees

   Two basic methods:
   1. A rule: that specifies in each ambiguous case which of the parse trees is
      the correct one. *disambbiguating rule*
      * associativity
   2. change the grammar
*** precedence and associativity
    A /left recursive/ rule makes its operators associate on the left
*** the dangling else problem
    \begin{grammar}
    <statement> ::= <if-stmt>
    \alt `other'

    <if-stmt> ::= `if' `(' <exp> `)' <statement>
    \alt `if' `(' <exp> `)' <statement> `else' <statement>
    \end{grammar}

    disambiguating rule is *most closely nested rule*.
    grammar is
    \begin{grammar}
    <statement> -> <matched-stmt>
    \alt <unmatched-stmt>

    <matched-stmt> -> `if' `(' <exp> `)' <matched-stmt> `else' <matched-stmt>
    \alt `other'

    <unmatched-stmt> -> `if' `(' <exp> `)' <statement>
    \alt `if' `(' <exp> `)' <matched-stmt> `else' <unmatched-stmt>

    <exp> -> `0'
    \alt `1'
    \end{grammar}
*** inessential ambiguity
    sometimes a grammar may be ambiguous and yet always produce unique /abstract/
    /syntax tree/.

    *inessential ambiguity*: the associated semantics don't depend on what
     disambiguating rule is used
*** extended notations: EBNF and syntax diagrams
    $A\to A\;\alpha\mid\beta\Longrightarrow A\to\beta\;\{\alpha\}$.
    $A\to\alpha\; A\mid\beta\Longrightarrow A\to\{\alpha\}\;\beta$
** Formal properties of context-free language
   A context-free grammar consists of the following
   1. T terminals
   2. N nonterminals
   3. P grammar rules
   4. S start symbol

   *sentential form* a string a in $(T\cup N)*$

   A grammar G is *ambiguous* if there exists a string $w\in L(G)$ s.t. w has two
   distinct parse trees

* Chap4 top-down parsing
** Top-down parsing by recursive-descent
   not easy and use EBNF
   \begin{grammar}
   <if-stmt> ::= `if' `(' <exp> `)' <statement>
   \alt `if' `(' <exp> `)' <statement> `else' <statement>
   \end{grammar}
   to if-stmt -> if (exp) statement [else statement]
** LL(1) parsing
   use an explicit stack rather than recursive calls.
   \begin{grammar}
   <S> ::= <E> `+' <S>
   \alt <E>

   <E> ::= `num'
   \alt `(' <S> `)'
   \end{grammar}
   .
   | partly-derived string | lookahead | parsed part | unparsed part |
   |-----------------------+-----------+-------------+---------------|
   | S                     |         ( |             | (1+2+(3+4))+5 |
   | E+S                   |         ( |             | (1+2+(3+4))+5 |
   | (S)+S                 |         1 | (           |  1+2+(3+4))+5 |
   | (E+S)+S               |         1 | (           |  1+2+(3+4))+5 |
   | (1+S)+S               |         2 | (1+         |    2+(3+4))+5 |
   | (1+E+S)+S             |         2 | (1+         |    2+(3+4))+5 |
   | (1+2+S)+S             |         ( | (1+2+(      |      (3+4))+5 |

   For $S\to(S)\; S\mid\epsilon$
   | step | parsing | input | action  |
   |------+---------+-------+---------|
   |    1 | $S      | ()$   | S->(S)S |
   |    2 | $S)S(   | ()$   | match   |
   |    3 | $S)S    | )$    | S->e    |
   |    4 | $S)     | )$    | match   |
   |    5 | $S      | $     | S->e    |
   |    6 | $       | $     | match   |

   Two actions:
   1. generate
   2. match: match a token on top of the stack with the next input token

   This corresponds to the leftmost derivation. *characteristic of top-down
   parsing*
*** LL(1) parsing table
   parsing table
   | M[N,T] | (       | )    | $    |
   |--------+---------+------+------|
   | S      | S->(S)S | S->e | S->e |

   M is the set of non-terminals.
   T is the set of terminals or tokens including $

   Table-constructing rule:
   1. if $A\to\alpha$ is a production choice and there is a derivation
      $\alpha\Rightarrow*a\beta$ where a is a token then add $A\to\alpha$ to
      M[A,a]
   2. if $A\to\alpha$ and
      $\alpha\Rightarrow*\epsilon,S\textdollar\textsterling\Rightarrow^*\beta
      Aa\gamma$, where S is the start symbol and a is a token(or $), then add
      $A\to\alpha$ to M[A,a]

   A grammar is LL(1) if LL(1) parsing table has at most one production in each entry
*** left recursion removal and left factoring
    *left recursion removal*
       * *immediate left recursion*: $exp\to exp\;+\;term|exp\;-\;term|term$
       * *indirect left recursion*: $A\to Bb$ and $B\to Aa$


    1. Simple immediate left recursion.
       $A\to A\alpha|\beta$ to $A\to\beta\;A'$ and $A'\to\alpha\;A'|\epsilon$
    2. general immediate left recursion.
       $A\to A\alpha_1|\dots|A\alpha_n|\beta_1|\dots|\beta_m$ to
       $A\to\beta_1A'|\dots|\beta_mA'$ and
       $A'\to\alpha_1A'|\dots|\alpha_nA'|\epsilon$
    3. general left recursion. grammars with no $\epsilon$-productions and no cycles


    doesn't change language, but changes the grammar and parse tree

    *left factoring*.
    $A\to\alpha\beta|\alpha\gamma$ to $A\to\alpha A'$ and $A'\to\beta\mid\gamma$
*** Syntax tree construction in LL(1) parsing
** First and follow sets
   X a grammar symbol(a terminal or non-terminal) or $\epsilon$. Then First(X)
   is
   1. if X is a terminal or $\epsilon$, then First(X)={X}
   2. if X is a non-terminal, for each $X\to X_1X_2\dots X_n$, First(X) contains
      First(X1) - {e}

   A non-terminal A is *nullable* iff there exists $A\Rightarrow^*\epsilon$ iff
   First(A) contains $\epsilon$

   Follow(A) is
   1. if A is start symbol, $ is in Follow(A)
   2. if $B\to\alpha A\gamma$, then
      $\text{First}(\gamma)-\{\epsilon\}\subseteq\text{Follow}(A)$
   3. if $B\to\alpha A\gamma, \epsilon\in\text{First}(\gamma)$, then Follow(A)
      contains Follow(B)
** Error recovery in top-down parsers
* Chap5 Bottom-up parsing
** Overview of bottom-up parsing
   + A bottom-up parser uses an *explicit stack* to perform a parse
   + The parsing stack will contain both tokens and nonterminals
     | $            | inputstring $ |
     |--------------+---------------|
     | ...          | ...           |
     | $StartSymbol | $accept       |
   + *right-most* derivation -- backward
     start with the tokens; end with the start symbol
     | (1+2+(3+4))+5 |
     | (E+2+(3+4))+5 |
     | (S+2+(3+4))+5 |
     | (S+E+(3+4))+5 |
     | (S+(3+4))+5   |
     | (S+(E+4))+5   |
     | (S+(S+4))+5   |
     | (S+(S+E))+5   |
     | (S+(S))+5     |
     | (S+E)+5       |
     | (S)+5         |
     | E+5           |
     | S+5           |
     | S+E           |
     | S             |
   + *parsing actions*: a sequence of *shift* and *reduce* operations
     *parser state*: a stack of terminals and non-terminals
     *current derivation step* = always stack + input
     | derivation    | step stack | unconsumed input |
     |---------------+------------+------------------|
     |               |            |              <r> |
     | (1+2+(3+4))+5 |            |    (1+2+(3+4))+5 |
     |               | (          |     1+2+(3+4))+5 |
     | (E+2+(3+4))+5 | (E         |      +2+(3+4))+5 |
     | (S+2+(3+4))+5 | (S         |      +2+(3+4))+5 |
     |               | (S+        |       2+(3+4))+5 |
     |               | (S+2       |        +(3+4))+5 |
     | (S+E+(3+4))+5 | (S+E       |        +(3+4))+5 |
   + 1. *shift*: shift a terminal from the front of the input to the top of the
     stack
     1. *reduce*: reduce a string α at the top of the stack to a nonterminal A,
        given the BNF choice A ⟶ α

     A bottom-up parser: *shift-reduce parser*
   + One further feature of bottom-up parsers： grammars are always augmented
     with a *new start symbol*. if S is the start symbol, a new start symbol S' is
     added to the grammar :  S' →S

   + example

     S'->S

     S ->(S)S|e

     S'=>S=>(S)S=>(S)=>()
     |   | Parsing stack | Input | Action             |
     |---+---------------+-------+--------------------|
     |   |               |   <r> |                    |
     | 1 | $             | ( ) $ | Shift              |
     | 2 | $ (           |   ) $ | Reduce  S -> ε    |
     | 3 | $ (S          |   ) $ | Shift              |
     | 4 | $ (S )        |     $ | Reduce  S -> ε    |
     | 5 | $ (S ) S      |     $ | Reduce S --> (S) S |
     | 6 | $S            |     $ | Reduce S'--> S     |
     | 7 | $S'           |     $ | Accept             |

   + example

     E'->E

     E->E+n|n

     E'=>E=>E+n=>n+n
     |   | Parsing stack | Input | Action        |
     |   |               |   <r> |               |
     | 1 | $             |  n+n$ | Shift         |
     | 2 | $n            |   +n$ | Reduce  E->n  |
     | 3 | $E            |   +n$ | Shift         |
     | 4 | $E+           |    n$ | Shift         |
     | 5 | $E+n          |     $ | Reduce E->E+n |
     | 6 | $E            |     $ | Reduce E'->E  |
     | 7 | $E'           |     $ | Accept        |
   + Right sentential form ::
     + A *sentential* form is any string derivable from the start symbol. Note
       that this includes the forms with non-terminals at intermediate steps as
       well.
     + A *right-sentential form* is a sentential form that occurs in a step of
       rightmost derivation (RMD).
       Each of the intermediate strings of terminals and nonterminals in such
       a derivation is called a right sentential form
       Each such sentential form is split between the parsing stack and the input
       during a shift-reduce parse
     + A *sentence* is a sentential form consisting only of terminals

     E,E+,E+n are *viable prefixes* of the right sentential form E+n.
     The sequence of symbols on the parsing stack is called *viable prefix* of the
     right sentential form
   + *handle*
     This string, together with the *position* in the right sentential form where it
     occurs, and the production used to reduced it, is called the *handle* of the right
     sentential form

     _determining the next handle in a parse is the main task of a shift-reduce parser_
** Finite automata of LR(0) items and LR(0) parsing
   + An *LR(0) item* of a context-free grammar: a production choice with a
     distinguished position in its right-hand side
   + If *A -> α*, *βγ = α*, then *A -> β · γ* is an LR(0) item
   + Example
     | S' -> S       |
     | S -> (S)S \ e |
     | S' -> ·S      |
     | S' -> S·      |
     | S -> ·(S)S    |
     | S -> (·S)S    |
     | S -> (S·)S    |
     | S -> (S)·S    |
     | S -> (S)S·    |
     | S -> ·        |
*** Finite automata of items
    + The LR(0) items: as the state of a finite automata
    + construct the DFA of sets of LR(0) using the subset construction from NFA
    + If X is a token or a nonterminal

      \begin{tikzpicture}
      [place/.style={circle,minimum size=5mm}]
      \node (x1) at (0,0) [place] {$A\to\alpha\cdot X\eta$};
      \node (x2) at (5,0) [place] {$A\to\alpha X\cdot\eta$};
      \draw [->] (x1) to node [above] {X} (x2);
      \end{tikzpicture}
    + If X is a token, then this transition corresponds to a shift of X from the
      input to the top of the stack during a parse
    + if X is a nonterminal,
      X will never appear as an input symbol

      \begin{tikzpicture}
      \node (x1) at (0,0) [circle] {$A\to\alpha\cdot X\eta$};
      \node (x2) at (5,0) [circle] {$X\to\cdot\beta$};
      \draw [->] (x1) to node [above] {$\epsilon$} (x2);
      \end{tikzpicture}
    + The *start state* of the NFA ↔ the *initial state* of the parser: the stack is
      empty
    + the solution is to augment the grammar by a single production S' -> S
    + *S'->·S* the *start state* of the NFA
*** The LR(0) parsing algorithm
    + the parsing stack to store: *symbols* and *state numbers*
    + pushing the new *state number* onto the parsing stack after each push of *a
      symbol*
    + Let s be the current state. Then actions are
      1. if state s contains any item of the form *A -> α·Xβ* (X is a terminal).
         Then the action is to shift the current input token onto the stack
      2. If state s contains any *complete item* (an item of the form *A->γ·*),
         then the action is to reduce by the rule *A->γ·*
         * A *reduction* by the rule *S'->S* where S' is the start state
         * *acceptance* if the input is empty
         * *Error* if the input is not empty
    + A grammar is *LR(0)* grammar if the above rules are unambiguous
    + A grammar is *LR(0)* iff
      * Each state is a shift state
      * A reduce state containing a single complete item
    + table
      | state | action | rule   | input | input | input | goto |
      |-------+--------+--------+-------+-------+-------+------|
      |       |        |        |     ( |     a | )     |    A |
      |     0 | shift  |        |     3 |     2 |       |    1 |
      |     1 | reduce | A'->A  |       |       |       |      |
      |     2 | reduce | A->(A) |       |       |       |      |
      |     3 | shift  |        |     3 |     2 |       |    4 |
      |     4 | shift  |        |       |       | 5     |      |
      |     5 | reduce | A->a   |       |       |       |      |
** SLR(1) Parsing (simple LR(1))
    + *definition*
      1. if state s contains any item of form $A\to\alpha\cdot X\beta$, then the
         action is to shift the current input token onto the stack, and the new
         state to be pushed on the stack is the state containing the item
         $A\to\alpha\cdot X\beta$
      2. if state s contains the complete item $A\to\gamma\cdot$, and _the next token in_
         _the input string is in Follow(A)_, then the action is to reduce by the
         rule $A\to\gamma$
         * A reduction by the rule *S'->S* where S' is the start state, this will
           happen only if the next input token is $
         * remove the string γ and all of its corresponding states from the parsing
           stack
         * back up in the DFA to the state from which the construction of γ begin
         * this state must contain an item of the form $B\to\alpha\cdot A\beta$.
           Push A to the stack, and push the state containing the item
           $B\to\alpha\cdot A\beta$
      3. if the next input token is s.t. neither of the above two cases applies,
         an error is declared
    + A grammar is *SLR(1)* iff for any state s
      1. for any item $A\to\alpha\cdot X\beta$ in s with X a terminal, there is no _complete_
         _item_ $B\to\gamma\cdot$ in s with X ∈ Follow(B)
      2. For any two complete item $A\to\alpha\cdot$ and $B\to\beta\cdot$ in s,
         $\text{Follow}(A)\cap\text{Follow(B)}=\emptyset$
    + right recursion can cause stack overflow
*** disambiguating rules for parsing conflicts
     + two kinds of parsing conflicts in SLR(1) parsing
       *shift-reduce* conflicts
       *reduce-reduce* conflicts
     + in the case of shift-reduce conflicts, there is a natural
       *disambiguaiting rule*: _always prefer shift over the reduce_
     +
*** limits of SLR(1) parsing power
** General LR(1) and LALR(1) parsing

   + the difficulty with the SLR(1) method:
     applies lookaheads after the construction of the DFA of LR(0) items
   + An *LR(1)* item is a pair consisting of an *LR(0)* item and a *lookahead* token
   + *LR(1)* item as
     *[A->α·β, a]*
     A->α·β is LR(0) item, a is a token
   + *definition of LR(1) transitions* main difference of LR(0) and LR(1)
     *[A->α·Xγ, a]*, X is any symbol, there is a transition on X to
     *[A->αX·γ,a]*
     *[A->α·Bγ,a]*, B nonterminal, there are ε-transitions to items *[B->·β,b]*
     for every *B->β* and for every token b in *First(γa)*
*** Finite automata of LR(1) items
    + *start* state
      S'->S
    + start item

      *[S'->·S, $]*
*** The LR(1) parsing algorithm
    + the general LR(1) parsing algorithm
      Let s be the current state.

      1. s:[A->α·Xβ,a], X terminal, X is the next token in the input string *shift*
      2. s: [A->α·,a], the next token in the input string is a *reduce*
      3. otherwise error
    + A grammar is *LR(1)* iff for any state s
      1. for any item *[A->α·β,a]* in s with X a terminal, there is no item in s
         of the form *[B->γ·,X]* (otherwise there is a _shift-reduce_ conflict
      2. there are no two item in s of the form *[A->α·,a]* and *[B->β·,a]*
** LALR(1) parsing
   + the size of the DFA of sets of LR(1) items is too large
   + first principle of LAIR(1) parsing
     the core of a state of DFA of LR(1) is a state of the DFA of LR(0) items
   + second principle of LAIR(1) parsing
     s₁,s₂ of DFA of LR(1) that have the same core, suppose there is a transition
     on the symbol X from s₁ to a state t₁, then there is also a transition on X
     from state s₂ to a state t₂, and the states t₁ and t₂ have the same core
   + if a grammar is LR(1) then the LALR(1) parsing table cannot have any
     shift-reduce conflicts, there may be reduce-reduce conflicts
   + if a grammar is SLR(1), then it's LALR(1)
   + compute the DFA of LALR(1) items directly from the DFA of LR(0) items through
     a process of *propagating lookaheads*
** Error recovery in Bottom-up parsers
   A bottom-up parser will detect an error when a blank entry is detected
* chap6 semantics analysis
** Attributes and attribute grammars
   *attribute*: any property of a programming language constructs. May be fixed prior to
   the compilation process or be only determinable during program execution

   *binding* of the attribute: the process of computing an attribute and associating its
   computed value with the language construct in question

   *binding time*: the time during the compilation/execution process when the binding of
   an attribute occurs

   *static attributes/dynamic attributes*: based on the difference of the binding time

   *type checker*: an analyzer.
   computes the data type attribute of all language entities for which
   data types are defined. And verifies that these types conform to the type rules of
   the language

   *type checking*: set of rules that ensure the type consistency of different constructs
   in the program. e.g. operands types and so on
*** attribute grammars
    * $X.a$: the value of a associated to X

      $X$ is a grammar symbol and $a$ is an attribute associated to $X$
    * *syntax-directed semantics*: attributes are associated directly with the grammar
      symbols of the language
    * given attributes $a_1, a_2,...,a_k$ for each grammar rule
      $X_0\to X_1\dots X_n$, the values of
      the attributes $X_i.a_j$ of each grammar symbol $X_i$ are related to the values of the
      attributes of the other symbols in the rule
    * an *attribute grammar*

      $X_i.a_j=f_{ij}(X_0.a_1,\dots,X_0.a_k,\dots,X_n.a_1,\dots,X_n.a_k)$
    * example

      For
      \begin{grammar}
      <number> ::= <number> <digit> \alt <digit>

      <digit> ::= `[0123456789]'
      \end{grammar}
      | grammar rule                      | semantic rules                               |
      |-----------------------------------+----------------------------------------------|
      | $number1 \to number2 \; digit$    | $number1.val=number2.val\times 10+digit.val$ |
      | $number\to digit$                 | $number.val=digit.val$                       |
      | $digit\to 0$                      | $digit.val=0$                                |


      \begin{forest}
      qtree,
      [{number\\($val=34*10+5=345$)}
       [{number\\($val=3*10+4=34$)}
        [{number\\$(val=3)$}
         [{digit\\$(val=3)$}
          [3]
         ]
        ]
        [{digit\\$(val=4)$} [4]]
       ]
       [{digit\\$(val=5)$} [5]]
      ]
      \end{forest}
*** simplifications and extensions to attribute grammars
    * *metalanguage* for the attribute grammar: the collection of expressions allowable in
      an attribute equation
    * *functions* can be added to the metalanguage whose definitions may be given elsewhere
    * *simplifications*
      1. using ambiguous grammar
      2. using abstract syntax tree instead of parse tree

** Algorithms for attribute computation

   * an edge from Xₘ.aₖ to Xᵢ.aⱼ expressing the dependency of Xᵢ.aⱼ on Xₘ.aₖ
*** dependency graphs and evaluation order
   + each grammar rule choice has an *associated dependency graph*
   + $X_i.a_j=f_{ij}(\dots,X_m.a_k,\dots)$

     an edge from each $X_m.a_k$ to $X_i.a_j$

       \ttfamily
       \begin{tikzpicture}
       [level 1/.style={sibling distance=20mm},
        level 2/.style={sibling distance=20mm},<-,baseline]
         \node {Num.val}
         child {node {Number.val}
           child {node {number.val}
             child {node {Digit.val}}}
           child {node {Digit.val}}}
         child {node {Digit.val}};
       \end{tikzpicture}
       \rmfamily
   + another example
     \begin{grammar}
     <decl> ::= <type> <var-list>

     <type> ::= `int' \alt `float'

     <var-list> ::= `id' `,' <var-list> \alt `id'
     \end{grammar}

     | grammar Rule                  | semantic Rules                      |
     |-------------------------------+-------------------------------------|
     | $decl\to type\;var-list$      | $var-list.dtype = type.dtype$       |
     | $type \to int$                | $type.dtype = integer$              |
     | $type \to float$              | $type.dtype = real$                 |
     | $var-list1\to id,\;var-list2$ | $id.dtype = var-list1.dtype$        |
     |                               | $var-list2.dtype = var-list1.dtype$ |
     | $var-list \to id$             | $id.dtype = var-list.dtype$         |

     \includegraphics[width=100mm]{DeclDependencyGraph.png}
   + *directed acyclic graphs* DAG
      topological sort

   How attribute values are found at the roots of the graph
   * *Parse tree method*: construction of the dependency graph is based on the
     specific parse tree at compile time, add complexity and need circularity
     detective
   * *Rule based method*: fix an order for attribute evaluation at compiler
     construction time. It depends on an analysis of the attribute equations, or
     semantic rules
*** synthesized and inherited attributes
    + *synthesized attributes*
      * an attribute is synthesized if all its dependencies point from child to parent in
        the parse tree
      * *S-attributed grammar*

        an attribute grammar where all the attributes are synthesized
    + *inherited attributes*

      inheritance from parent to siblings, from siblings to siblings.
*** attributes as parameters and returned values
*** The use of external data structures to store attributes values
    + Applicability
      * Not suitable to the method of *parameters* and *returned values*
      * particularly when the attribute values have significant structure
        and may be needed at arbitrary points during translation
      * Not reasonable to be stored in the syntax tree nodes
    + Ways:
      * external data structures: table, graphs and other data structures. One
        of the prime examples is the symbol table
      * replace attribute equations by calls to procedures representing
        operations on the appropriate data structure used to maintain the
        attribute values
*** The computation of attributes during parsing
    + *L-attributed*
      * An attribute grammar of $a_1,\dots,a_k$ is *L-attributed* if for each
        inherited attribute $a_j$ and each grammar rule $X_0\to X_1\dots X_n$
        the associated equations for a_j are

        $X_i.a_j=f_{ij}(X_0.a_1,\dots,X_0.a_k,X_1.a_1,\dots,X_1.a_k,\dots,X_{i-1}
        .a_1,\dots,X_{i-1}.a_k)$
    + *S-attributed grammar* is L-attributed
    + given an /L-attributed/ grammar where the /inherited/ attributes don't depend
      on the /synthesized/ attributes
      1. *Top-down parser*: a recursive-descent parser can evaluate all the
         attributes by turning the inherited attributes into parameters and
         synthesized attributes into returned values.
      2. *Bottom-up parser*: LR parsers are suited to handling primarily
         synthesized attributes, but are difficult for inherited attributes
    + $A\to B\;C\quad C.i=f(B.s)$ /s/ is a /synthesized/ attribute

      | Grammar Rule   | Semantic Rules             |
      |----------------+----------------------------|
      | $A\to BDC$     |                            |
      | $B\to\dots$    | compute $B.s$              |
      | $D\to\epsilon$ | $saved_i=f(valstack[top])$ |
      | $C\to\dots$    | $saved_i$ is available     |
*** The dependence of attributes computation on the syntax
    *Theorem*. Given an attribute grammar , _all inherited attributes can be
    changed into synthesized attributes_ by suitable modification of the grammar,
    without changing the language of the grammar. (Knuth[1968])


** The Symbol Table
   *semantic checks* refer to properties of identifiers in the program - their
   scope or type

   | NAME | KIND | TYPE              | ATTRIBUTES |
   |------+------+-------------------+------------|
   | foo  | fun  | int * int -> bool | extern     |
   |      |      |                   |            |
*** The structure of the symbol table
   1. Linear list
   2. Various search tree structures

      AVL, B tree
   3. hash tables

      best choice

      Collision resolution
      1. open addressing
      2. separate chaining

      The process of the hash function $f:\Sigma^*\to\mathbb{N}/(size-1)\mathbb{N}$

      Good solution: repeatedly use a constant $\alpha$ as multiplying factor

      $h_{i+1}=\alpha h_i+c_i, \quad h_0 = 0$

      Final hash value $h=h_n\mod size$. Typically $\alpha$ is a power of 2
*** Declarations
    * constant declarations
    * type declarations
    * variable declarations
    * procedure/function declarations
*** Scope rules and block structure
    two rules
    * Declaration before use
    * the most closely nested rule for block structure
*** interaction of same-level declarations
*** an extended example of an attribute grammar using a symbol table
    \begin{grammar}
    <S> ::= <exp>

    <exp> ::= `(' <exp> `)' \alt  <exp> `+' <exp>
    \alt `id' \alt `num' \alt `let' <dec-list> `in' <exp>

    <dec-list> ::= <dec-list> `,' <decl> \alt <decl>

    <decl> ::= `id' `=' <exp>
    \end{grammar}

    Three attributes
    * ~err~: synthesize attribute. represent error
    * ~symbol~: inherited attribute. represent the symbol table
    * ~nestlevel~: inherited attribute, nonnegtive integer. represent the current
      nesting level of the let blocks
\ttfamily
| Grammar Rule                    | Semantic Rules                                   |
|---------------------------------+--------------------------------------------------|
| /S $\to$ exp/                     | exp.symtab = emptytable                          |
|                                 | exp.nestlevel = 0                                |
|                                 | S.err = exp.err                                  |
|---------------------------------+--------------------------------------------------|
| /exp1 $\to$ exp2+exp3/            | exp2.symtab=exp1.symtab                          |
|                                 | exp3.symtab=exp1.symtab                          |
|                                 | exp2.nestlevel=exp1.nestlevel                    |
|                                 | exp3.nestlevel=exp1.nestlevel                    |
|                                 | exp1.err = exp2.err or exp3.err                  |
|---------------------------------+--------------------------------------------------|
| /exp1 $\to$ (exp2)/               | exp2.symtab =exp1.symtab                         |
|                                 | exp2.nestlevel =exp1.nestlevel                   |
|                                 | exp1.err = exp2.err                              |
|---------------------------------+--------------------------------------------------|
| /exp $\to$ id/                    | exp.err = not isin(exp.symtab, id.name)          |
|---------------------------------+--------------------------------------------------|
| /exp $\to$ num/                   | exp.err = false                                  |
|---------------------------------+--------------------------------------------------|
| /exp1 $\to$ let dec-list in exp2/ | dec-list.intab=exp1.symtab                       |
|                                 | dec-list.nestlevel=exp1.nestlevel+1              |
|                                 | exp2.symtab=dec-list.outtab                      |
|                                 | exp2.nestlevel=dec-list.nestlevel                |
|                                 | exp1.err = (dec-list.outtab=errtab) or exp2.err  |
|---------------------------------+--------------------------------------------------|
| /dec-list1 $\to$ dec-list2,decl/  | dec-list2.intab= dec-list1.intab                 |
|                                 | dec-list2.nestlevel=dec-list1.nestlevel          |
|                                 | decl.intab=dec-list2.outtab                      |
|                                 | decl.nestlevel=dec-list2.nestlevel               |
|                                 | decl-list1.outtab=decl.outtab                    |
|---------------------------------+--------------------------------------------------|
| /dec-list $\to$ decl/             | decl.intab = dec-list.intab                      |
|                                 | decl.nestlevel=dec-list.nestlevel                |
|                                 | dec-list.outtab=decl.outtab                      |
|---------------------------------+--------------------------------------------------|
| /decl $\to$ id = exp/             | exp.symtab = decl.intab                          |
|                                 | exp.nestlevel=decl.nestlevel                     |
|                                 | decl.outtab =                                    |
|                                 | if(decl.intab = errtab)or exp.err                |
|                                 | then errtab                                      |
|                                 | else                                             |
|                                 | if (lookup(decl.intab, id.name)= decl.nestlevel) |
|                                 | then errtab                                      |
|                                 | else                                             |
|                                 | insert(decl.intab,id.name,decl.nestlevel)        |
\rmfamily

** Data types and type checking
   Type inference. Type checking

*** type names, type declarations and recursive type

*** type equivalence
    two type expression represent the same type

    *structural equivalence*: two types are the same if and only if they have the same structure

    *name equivalence*: two type expressions are equivalent if and only if they are either the
    the same simple type or are the same type name

    *declaration equivalence*: weaker version of name equivalence. $t2=t1$ are interpreted
    as establishing type aliases rather than new types

*** type inference and type checking

*** additional topics in type checking
    * *overloading*
    * *type conversion and coercion*
* Chap7 runtime environments
** memory organization during program execution
   | code area          |
   | global/static area |
   | stack              |
   | free space         |
   | heap               |


   *procedure activation record*
   | space for arguments(parameters)                             |
   |-------------------------------------------------------------|
   | space for bookkeeping information, including return address |
   |-------------------------------------------------------------|
   | space for local data                                        |
   |-------------------------------------------------------------|
   | space for local temporaries                                 |

   *processor registers*
   * part of the structure of the runtime environment
   * special-purpose registers
     + PC :: program counter
     + SP :: stack pointer
     + FP :: frame pointer
     + AP :: argument pointer

   *calling sequence*
   1. the allocation of memory for the activation record
   2. the computation and storing of the arguments
   3. the storing and setting of necessary registers to affect the call

   *returning sequence*
   1. the placing of the return value where it can be accessed by the caller
   2. the readjustment of registers
   3. the possible releasing for activation record memory
** fully static runtime environment
   all data are static, remaining fixed in memory for the duration of program execution

   _No pointer or dynamic allocation. no recursive procedure calling_

   entire program memory
   * the global variables and all variables are allocated statically
   * each procedure has only a single activation record
   * all variables can be accessed directly via fixed address
   * no extra information about the environment needs to be kept in an
     activation record

   the calling sequence(simple)
   1. each argument is computed and stored into its appropriate parameter location
      in the activation of the procedure being called
   2. the *return address* of the caller is saved
   3. a jump is made to the begining of the code of the called procedure
   4. on return, a simple jump is made to the return address
   

   | code for main procedure             | code area |
   | code for procedure 1                | code area |
   | ...                                 | code area |
   | code for procedure n                | code area |
   | global data area                    | data area |
   | activation record of main procedure | data area |
   | ...                                 | data area |


** stack-based runtime environments
   for a language where
   * recursive calls are allowed
   * local variables are newly allocated at each call
   * activation records cannot be allocated statically


   the stack of *activation records* grows and shrinks with the main of calls in
   the executing program

   Each procedure may have several *different activation records* on the call
   stack at one time
   
   In a language where _all procedures are global_, the stack-based environment
   requires two things
   1. frame point, =fp=, a pointer to the current activation record to allow
      access to local variable.

      *control link* or *dynamic link*, a point to a record of the immediately
      preceding activation

      /fp/ points to the control link of the current activation record
      
      
   2. stack pointer, =sp=, a pointer to the last location allocated on the call stack
*** stack-based environments without local procedures


    \includegraphics[width=150mm]{fp}

    the calling sequence
    1. compute the /arguments/ and store them in their correct positions in the
       new activation record of the procedure.

       because C parameters' order is reverse because of an indefinite number of
       arguments
    2. store the /fp/ as the control link in the new activation record
    3. change the /fp/ s.t. it points to the beginning of the new activation
       record
    4. store the /return address/ in the new activation record
    5. perform a /jump/ to the code of the procedure to be called


    when a procedure exits
    1. copy the /fp/ to the /sp/
    2. load the control link into the /fp/
    3. perform a /jump/ to the return address
    4. change the /sp/ to pop the arguments


    Dealing with variable-length data
    * C compiler typically deal with this by pushing the arguments to a call *in
      reverse order* onto the runtime stack. The first parameter is always 
      located at a fixed offset from the fp in the implementation described
      above. 
*** stack-based environment with local procedures
    *access link(static link)*: represents the defining environment of the
     procedure; 

    *control link*: represents the calling environment of the procedure. 

    \includegraphics[width=150mm]{AccessLink}


    The calling sequence
    1. The access link must be pushed onto the runtime stack just before the /fp/
       during a call
    2. The /sp/ must be adjusted by an extra amount to remove the access link
       after an exit 
** Dynamic memory
   A stack-based environment will result in a dangling reference

   For example
   #+BEGIN_SRC c
     int * dangle(void) {
         int x;
         return &x;
     }
   #+END_SRC
   An assignment =addr=danle()=
*** fully dynamic runtime environment
    more complex instance of a dangling reference occurs if a local function can
    be returned by a call


    A stack-based runtime environment is inadequate

    A more general form of environment *fully dynamic environment*. It can
    deallocate activation records only when all references to them have
    disappear 
    

    Garbage collection
    * The tracking of references during execution
    * the ability to find and deallocate in accessible areas of memory at
      arbitrary times during execution

      
    * In fully dynamic environment, the basic structure of activation record
      remains the same
    * when control is returned to the caller, the exited activation record remains
      in memory, to be de-allocated at some later time
*** dynamic memory in object-oriented languages
    features: Objects, methods, inheritance, and dynamic binding
*** heap management
    *Heap* the data structure
    1. allocate

    2. free


    standard method for maintaining the heap
    1. a circular linked list of free blocks
    2. memory is taken by malloc
    3. memory is returned by free


    Another method: use a circular linked list data structure that keep track of
    both allocated and free block.  
*** automatic management of the heap
    garbega collection:  the process of reclamation of allocated but no longer
    used storage without an explicit call to free.  


    1. *mark and sweep gargage collection*
       no memory is freed until a call to malloc fails
       1. follows all pointers recursively, starting with all currently
          accessible pointer values and marks each block of storage reached
       2. sweeps linearly through memory
          return unmarked blocks to free memory

    2. *stop-and-copy or two-space garbage collection*
    3. *general gargabge collection*
** parameter passing mechanisms
*** pass by value
    the arguments are expressions that are evaluated at the time of the call
*** pass by reference
    pass by reference passes the location of the variable
*** pass by value-result
    known as copy-in, copy-out

    
    the final value of the parameter is copied back out to the location of the
    argument 
*** pass by name
* chap8 Code generation
** Intermediate code and data structures for code generation
*** Three-address code
    ~x = y op z~

    x is an address

    For ~2*a+(b-3)~, it becomes
    | ~T1 = 2 * a~   |
    | ~T2 = b -3~    |
    | ~T3 = T1 + T2~ |
*** Data structures for the implementation of three address code
    * Four fields are necessary: one for operation and three for the addresses
    * Those instructions that need fewer than three addresses, one or more of
      the address fields is given a null or "empty" value
    * the entire sequence of three-address instructions is implemented as an
      array or linked list
*** P-code
    ~2 * a + (b - 3)~

    | ldc 2 | load constant 2          |
    | lod a | load value of variable a |
    | mpi   | integer multiplication   |
    | lod b |                          |
    | ldc 3 |                          |
    | sbi   | integer subtraction      |
    | adi   | integer addition         |


    ~x:=y+1~

    | lda x | load address of x                         |
    | lod y |                                           |
    | ldc 1 |                                           |
    | adi   |                                           |
    | sto   | store top to address below top & pop both |
** Basic code generation techniques
*** Intermediate code or target code as a synthesized attribute
*** Practical code generation
*** generation of target code from intermediate code
    1. *macro expansion*
    2. *static simulation*
** Code generation of data structure references
** Code generation of control statements and logical expressions
*** Code generation for If- and while- statements
    two kinds of jump
    * unconditional jump ~goto~
    * jumps when the condition is false
