
#+TITLE: Artificial Intelligence
#+EMAIL: gouziwu@gmail.com
#+AUTHOR: wu
#+EXPORT_FILE_NAME: latex/ArtificialIntelligence/ArtificialIntelligence.tex
#+LATEX_HEADER: \graphicspath{{../../images/ArtificialIntelligence/}}
#+LATEX_HEADER: \input{preamble.tex}
#+OPTIONS:
* scope [0%]
  - [ ] uninformed search and informed search
  - [ ] adversarial search: minimax, evaluation functions, alpha-beta search,
    stochasitc search
  - [ ] Basic concept for Statistical Learning and modeling
    - [ ] Probability Theory
    - [ ] Model selection
    - [ ] The curse of Dimensionality
    - [ ] Decision Theory
    - [ ] Information Theory
    - [ ] Probability Distribution
  - [ ] Supervised Learning
    - [ ] Linear model for regression
    - [ ] Linear basis function models
    - [ ] Linear model for classification
    - [ ] Adaboosting
  - [ ] Unsupervised Learning
    - [ ] K-means Clustering
    - [ ] GMM & EM algorithm
    - [ ] Principal Component Analysis
  - [ ] Deep Learning
    - [ ] Stochastic Gradient Descent
    - [ ] Backpropagation
    - [ ] Feedforward Neural Network
    - [ ] Convolutional Neural Networks
    - [ ] Deep learning in CV (localization)
    - [ ] Recurrent Neural Network (LSTM, GRU)
  - [ ] Reinforcement learning
    - [ ] Reinforcement learning
    - [ ] Markov Decision Process
    - [ ] Value-based Optimization; Q-learning
* Basic concepts for filling in blanks or single choice [0%]
  - [ ] Uninformed search (blind search)
    - [ ] Problem definition, initial state, actions, transition model, goal
      test, path cost, step cost, frontier (open list), loopy path, explored set
      (closed set), tree-search, graph-search, queue, completeness, optimality,
      time complexity, space complexity 
    - [ ] Breadth-first search (BFS)
    - [ ] Depth-first search (DFS)
    - [ ] Uniform-cost search (UCS), Depth-limited search (DLS), iterative
      deepening search (IDS) 
  - [ ] informed (heuristic) search
    - [ ] Heuristic function h(n), evaluation function f(n), path cost g(n)
    - [ ] Best-first search: use f(n) instead of g(n)
    - [ ] Greedy best-first search: f(n) = h(n)
    - [ ] A* search: f(n) = g(n) + h(n), it is identical to Uniform-Cost-Search
      except that A* uses g+h instead of g
    - [ ] Conditions for A* optimality: Admissibility and Consistency
  - [ ] Adversarial search
    - [ ] Minimax search: min node, max node, utility
    - [ ] Alpha-Beta Pruning Search: alpha value, beta value, pruning
  - [ ] Uninformed search vs. informed search
* solving problems by search
  *problem-solving agent*
  * *goal*
  * *goal information* is the 1st step in problem-solving, based on the
    current situation and the agent’s performance measure
  * *problem formulation* is the process of deciding what actions and
    states to consider, given a goal 
  * *search*
  * *execution phase*


  formulate—search—execution


  type of search
  * *uninformed search algorithms*

    algorithms that are given no information about the problem other
    than its definition. Although some of these algorithms can solve
    any solvable problem, none of them can do so efficiently
  * *informed search algorithms*
    
    
  The types of Problem-solving by Search
  * Deterministic, fully observable

    Agent knows exactly which state it will be in

    solution is a sequence
  * non-observable

    Agent may have no idea where it is

    solution (if any) is a sequence
  * Nondeterministic and/or partially observable

    percepts provide new information about current state
    
    solution is a tree or policy

    often interleave search, execution
  * Unknown state space
* Inference and Reasoning
** Propositional logic
** Predicate logic
** First Order Inductive Learner
   *knowledge graph*: node = entity, edge = relation.
   triplet (head entity, relation, tail entity)
* Statistical learning and modeling
** Machine Learning: the concept
*** Example and concept
    + Supervised learning problems :: 
         applications in which the *training data* comprises examples of the input
         vectors along with their corresponding *target vectors* are known

         classification and regression
    + Unsupervised learning problems :: 
         the training data consists of a set of input vectors X *without any
         corresponding target values*
         
         density estimation, clustering, hidden markov models
    + Reinforcement learning problem :: 
         finding suitable actions to take in a given situation in order to
         maximize a reward. Here the learning algorithm is not given examples of
         optimal outputs, in contrast to supervised learning, but must instead
         discover them by a process of trial and error. A general feature of
         reinforcement learning is the trade-off between exploration and exploitation

  types of machine learning
  - supervised learning
    * classification: the output is categorical or nominal variable
    * regression: the output is read-valued variable
  - unsupervised learning
  - semi-supervised learning
  - reinforcement learning
  - deep learning
*** supervised learning: important concepts
    * Data: labeled instances $<\bl{x}_i,\bl{y}>$
    * features: attribute-value pairs which characterize each $\bl{x}$
    * learning a discrete function: *classification*
    * learning a continuous function: *regression*

    *Classification* - A two-step process
    * *model construction*
    * *model usage*

    *regression*
    * Example: price of a used car
      
      $\bl{x}$: car attributes. $\bl{y}=g(\bl{x}\mid\bl{\theta})$: price. $g$:
      model. $\theta$ parameter set.
** example: polynomial curve fitting
** probability theory review and notation
   rules of probability
   * *sum rule* $p(X)=\displaystyle\sum_Yp(X,Y)$
   * *product rule* $p(X,Y)=p(Y|X)p(X)$

   Bayes' Theorem: $p(Y|X)=\frac{p(X|Y)p(Y)}{p(X)}$. Using sum rule
   $p(X)=\displaystyle\sum_Yp(X|Y)p(Y)$

   probability densities. 
   \begin{align*}
   p(x\in(a,b))&=\int_a^bp(x)dx\\
   P(z)&=\int_{-\infty}^z p(x)dx\\
   \int_{-\infty}^\infty p(x)dx&=1\quad p(x)\le0
   \end{align*}


   *expectation* $\mathbb{E}[f]=
   \begin{cases}
   \displaystyle\sum_{x}p(x)f(x) & \text{discrete variables}\\
   \int p(x)f(x)dx & \text{continuous variables}
   \end{cases}$. In either cases,
   $\mathbb{E}[f]\approx\frac{1}{N}\displaystyle\sum_{n=1}^N f(x_n)$.
   *conditional expectation*: $\mathbb{E}_x[f| y]=\displaystyle\sum_xp(x| y)f(x)$.

   The *variance* of $f(x)$ is

   \begin{align*}
   var[f]&=\mathbb{E}[(f(x)-\mathbb{E}[f(x)])^2]\\
   &=\mathbb{E}[f(x)^2-2f(x)\mathbb{E}[f(x)]+\mathbb{E}[f(x)]^2]\\
   &=\mathbb{E}[f(x)^2]-\mathbb{E}[f(x)]^2
   \end{align*}


   The *covariance* is

   \begin{align*}
   cov[x,y]&=\mathbb{E}_{x,y}[(x-\mathbb{E}[x])(y-\mathbb{E}[y])]\\
   &=\mathbb{E}_{x,y}[xy]-\mathbb{E}[x]\mathbb{E}[y]
   \end{align*}


   /the variance of the sum of two independent random variables is the sum of/
   /variance/. Given
   #+ATTR_LATEX: :align c|c
   | X       | probability |
   |---------+-------------|
   | $x_1$   | $p_1$       |
   | $\dots$ | $\dots$     |
   | $x_n$   | $p_n$       |

   #+attr_latex: :align c|c
   | Y       | probability |
   |---------+-------------|
   | /       |             |
   | $y_1$   | $q_1$       |
   | $\dots$ | $\dots$     |
   | $y_m$   | $q_m$       |
   \begin{align*}
   var(X+Y)=var(X)+var(Y)
   \end{align*}

   In case of two vectors of random variables $\bl{x}$ and $\bl{y}$, the
   covariance is a matrix
   \begin{align*}
   cov[\bl{x},\bl{y}]&=\mathbb{E}_{\bl{x},\bl{y}}[(\bl{x}-\mathbb{E}[\bl{x}])(\bl{y}^T
   -\mathbb{E}[\bl{y}^T])]\\
   &=\mathbb{E}_{\bl{x},\bl{y}}[\bl{xy}^T]-\mathbb{E}[\bl{x}]\mathbb{E}[\bl{y}^T]
   \end{align*}

   *Bayesian probabilities*: $P(A|B)=\frac{P(B|A)P(A)}{P(B)}$. For a data set 
   $\mathcal{D}=\{t_1,\dots,t_n\}$ and assumption $w$,
   $p(w|\mathcal{D})=\frac{p(\mathcal{D}|w)p(w)}{p(\mathcal{D})}$. $p(w)$ is
   *prior probability*, $p(\mathcal{D}|w)$ is *likelihood* (the probability
   $\mathcal{D}$ happens). Hence 
   \begin{equation*}
   \text{posterior}\propto\text{likelihood}\times\text{prior}
   \end{equation*}

   *Gaussian distribution*.
   \begin{equation*}
   \mathcal{N}(x|\mu,\sigma^2)=\frac{1}{(2\pi\sigma^2)^{1/2}}\exp\left\{
   -\frac{1}{2\sigma^2}(x-\mu)^2\right\}
   \end{equation*}
   $\mu$ is called *mean*, $\sigma^2$ is called *variance*, $\sigma$ *standard
   deviation*, $\beta=1/\sigma^2$ *precision*
   \begin{align*}
   \mathbb{E}[x]&=\int_{-\infty}^\infty\mathcal{N}(x|\mu,\sigma^2)xdx=\mu\\
   \mathbb{E}[x^2]&=\int_{-\infty}^\infty\mathcal{N}(x|\mu,\sigma^2)x^2dx=\mu^2
   +\sigma^2\\
   var[x]&=\mathbb{E}[x^2]-\mathbb{E}[x]^2=\sigma^2\\
   \end{align*}
   For $D$-dimensional vector $\bl{x}$ of continuous variables
   \begin{equation*}
   \mathcal{N}(\bl{x}|\bl{\mu},\bl{\Sigma})=\frac{1}{(2\pi)^{D/2}}\frac{1}
   {\abs{\bl{\Sigma}}^{1/2}}\exp\left\{-\frac{1}{2}(\bl{x}-\bl{\mu})^T
   \bl{\Sigma^{-1}}(\bl{x}-\bl{\mu})\right\}
   \end{equation*}

   To determine values for the unknown parameters given $\mu$ and $\sigma^2$ by
   maximizing the likelihood function. Use log.
   \begin{align*}
   P(\bl{X}|\mu,\sigma^2)&=\displaystyle\prod_{n=1}^N\mathcal{N}(x_n|\mu,\sigma^2)\\
   \Rightarrow \ln P(\bl{X}|\mu,\sigma^2)&=-\frac{1}{2\sigma^2}
   \displaystyle\sum_{n=1}^N(x_n-\mu)^2-\frac{N}{2}\ln\sigma^2-\frac{N}{2}\ln(2\pi)\\
   \end{align*}
   Hence $\mu_{ML}=\frac{1}{N}\displaystyle\sum_{n=1}^Nx_n$,
   $\sigma^2_{ML}=\frac{1}{N}\displaystyle\sum_{n=1}^N(x_n-\mu_{ML})^2$ by
   partial derivative. Maximum likelihood estimator for mean is unbiased, that
   is, $\mathbb{E}(\mu_{ML})=\mu$. Maximum likelihood estimator for variance is
   biased. $\mathbb{E}(\sigma_{ML}^2)=\mathbb{E}(x^2)-\mathbb{E}(\mu_{ML}^2)=
   \frac{N-1}{N}\sigma_x^2$
** information theory
   *entropy*: measuring uncertainty of a random variable $X$.
   $H(X)=H(p)=-\displaystyle\sum_{x\in\Omega}p(x)\log p(x)$ where $\Omega$ is
   all possible values and define $0\log0=0,\log=\log_2$

   $H(X)=\displaystyle\sum_{x\in\Omega}p(x)\log_2\frac{1}{p(x)}=
   E(\log_2\frac{1}{p(x)})$. And "information of $x$"​="#bits to code $x$"​=$-\log
   p(x)$
   
   *Kullback-Leibler divergence*: comparing two distributions
** model selection
   *cross-validation*
   \includegraphics[width=100mm]{CrossValidation}

   split training data into *training set* and *validation set*. Train different
   models on training set and choose model with minimum error on validation set.
** decision theory
   Suppose we have an input vector $\bl{x}$ together with a corresponding vector
   $\bl{t}$ of target variables and our goal is to predict $\bl{t}$ given new
   value for $\bl{x}$. The joint probability distribution $p(\bl{x},\bl{t})$
   provides a complete summary of the uncertainty with these variables
* Statistical learning and modeling - Supervised learning
** Basic concepts
   + *Linearly separable*
     * decision regions:
       
       input space is divided into several regions
     * decision boundaries:
       - under linear models, it's a linear function
       - (D-1)-dimensional hyper-plane within the D-dimensional input space
   + *representation of class labels*
     * Two classes K = 2
     * K classes
       - 1-of-K coding scheme $\bl{t}=(0,0,1,0,0)^T$
     * Predict discrete class labels
       - linear model prediction $y(\bl{x})=\bl{w}^T\bl{x}+w_0$
         w: weight vector, w_0 bias/threshold
       - nonlinear function $f(.):R\to(0,1)$
       - generalized linear models
         $y(\bl{x})=f(\bl{w}^T\bl{x}+w_0)$
         f:activation function
       - dicision surface
         $y(\bl{x})=\text{constant}\to \bl{w}^T\bl{x}+w_0=\text{constant}$
   + *Three classification approaches*
     * discriminant function
       - least squares approach
       - fisher's linear discriminant
       - the perceptron algorithm of rosenblatt
     * use discriminant functions directly and don't compute probabilities

       Given discriminant functions $f_1(\bl{x}),\dots,f_K(\bl{x})$. Classify
       $\bl{x}$ as class $\mathcal{C}_k$ iff $f_k(\bl{x})>f_j(\bl{x}),\forall
       j\neq k$

       * *least-squares approach*: making the model predictions as close as
         possible to a set of target values
       * *fisher's linear discriminant*: maximum class separation in the ouput
         space
       * *the perceptron algorithm of rosenblatt*
     * generative approach
       - model the class-conditional densities and the class priors
       - compute posterior probabilities through Bayes's theorem

         $\underbrace{p(\mathcal{C}_k|\bl{x})}_\text{posterior for class}=
         \frac{\overbrace{p(\bl{x}|\mathcal{C}_k)}^\text{class conditional density}
         \overbrace{p(\mathcal{C}_k)}^\text{class prior}}{p(\bl{x})}=
         \frac{p(\bl{x}|\mathcal{C}_k)p(\mathcal{C}_k)}{\sum_{j}p(\bl{x}|\mathcal{C}_j)
         p(\mathcal{C}_j)}$
** discriminant functions
*** Two classes
    + Linear discriminant function $y(\bl{x})=\bl{w}^T\bl{x}+w_0$
      - Dicision surface $\Omega:y(\bl{x})=0$
      - the normal distant from the origin to the dicision surface
        $\frac{\bl{w}^T\bl{x}}{\norm{\bl{w}}}=-\frac{w_0}{\norm{\bl{w}}}$
      - if $x_A,x_B$ lie on the decision surface $y(\bl{x}_A)=y(\bl{x}_B)=0$,
        then $\bl{w}^T(\bl{x}_A-\bl{x}_B)=0$. hence w is orthogonal to every
        vector lying within Ω. $\frac{\bl{w}}{\norm{\bl{w}}}$ is the normal
        vector of Ω

      - $\bl{x}=\bl{x}_\perp+r\frac{\bl{w}}{\norm{\bl{w}}}$ hence
        $r=\frac{y(\bl{x})}{\norm{\bl{w}}}$. $y(\bl{x}_\perp)=0\to
        \bl{w}^T\bl{x}=-w_0+r\frac{\bl{w}^T\bl{w}}{\norm{\bl{w}}}$ 
      - $\tilde{\bl{w}}=(w_0,\bl{w}), \tilde{\bl{x}}=(x_0,\bl{x}),
        y(\bl{x})=\tilde{\bl{w}}^T\tilde{\bl{x}}$
*** K-class
    + One-versus-the-rest classifier
      K - 1 classifiers each of which solves a two-class problem
    + One-versus-one classifier
      K(K-1)/2 binary discriminant functions
    + single K-class discriminant comprising K linear functions
      $y_k(\bl{x})=\bl{w}_k^T\bl{x}+w_{k_0}$
      - assigning a point x to class $\mathcal{C}_k$ if
        $y_k(\bl{x}>y_j(\bl{x}))$ for all j≠k
      - dicision boundary between class $\mathcal{C}_k, \mathcal{C}_j$ is given
        $y_k(\bl{x})=y_j(\bl{x})\to
        (\bl{w}_k-\bl{w}_j)^T\bl{x}+(w_{k_0}-w_{j_0})=0$
      - $\mathcal{R}_k$ is singly connected convex
      - $\hat{\bl{x}}=\lambda\bl{x}_A+(1-\lambda)\bl{x}_B$ where $0\le\lambda\le
        1$, $y_k(\hat{\bl{x}})=\lambda y_k(\bl{x}_A)+(1-\lambda)y_k(\bl{x}_B)$
        and hence $\hat{x}$ also lies inside $\mathcal{R}_k$
*** Learning the parameters of linear discriminant functions
**** Linear basis function models
     *linear regression*:
     $y(\bl{x},\bl{w})=w_0+w_1x_1+\dots+w_Dx_D=\bl{w}^T\bl{x}$.

     For nonlinear functions $\phi_j$,
     $y(\bl{x},\bl{w})=w_0+\displaystyle\sum_{j=1}^{M-1}
     w_j\phi_j(\bl{x})=\bl{w}^T\bl{\phi(\bl{x})}$ where $\phi_j(\bl{x})$ are
     *basis functions* 
**** *parameter optimization via maximum likelihood*

     Assume target variable $t$ is given by a deterministic function
     $y(\bl{x},\bl{w})$ with additive Gaussian noice so that
     $t=y(\bl{x},\bl{w})+\epsilon$ where $\epsilon$ is a zero mean Gaussian
     random variable with precision $\beta$, hence we can write
     \begin{equation*}
     p(t|\bl{x},\bl{w},\beta)=\mathcal{N}(t|y(\bl{x},\bl{w}),\beta^{-1})
     \end{equation*}
     and $\mathbb{E}(t|\bl{x})=\int tp(t|\bl{x})dt=y(\bl{x},\bl{w})$

     For data set $\bl{X}=\{\bl{x}_1,\dots,\bl{x}_n\},\bl{t}=(t_1,\dots,t_n)^T$,
     $p(\bl{t}|\bl{X},\bl{w},\beta)=\displaystyle\prod_{n=1}^N\mathcal{N}(t_n|
     \bl{w}^T\bl{\phi}(\bl{x}_n),\beta^{-1})$

     $\ln p(\bl{t}|\bl{w},\beta)=\displaystyle\sum_{n=1}^N\ln\mathcal{N}(t_n|
     \bl{w}^T\bl{\phi}(\bl{x}_n),\beta^{-1})=\frac{N}{2}\ln\beta-\frac{N}{2}\ln(2\pi)-
     \beta E_D(\bl{w})$

     $E_D(\bl{w})=\frac{1}{2}\displaystyle\sum_{n=1}^N
     \left\{t_n-\bl{w}^T\bl{\phi}(\bl{x}_n)\right\}^2=
     \frac{1}{2}\norm{t-\Phi\bl{w}}$ is sum-of-squares error function

     solve $\bl{w}$ by maximum likelihood.
     \begin{equation*}
     \nabla\ln p(\bl{t}|\bl{w},\beta)=\displaystyle\sum_{n=1}^N
     \left\{t_n-\bl{w}^T\bl{\phi}(\bl{x}_n)\right\}\phi(\bl{x}_n)^T
     \end{equation*}
     \begin{equation*}
     0=\displaystyle\sum_{n=1}^N t_n\bl{\phi}(\bl{x}_n)^T-\bl{w}^T
     (\displaystyle\sum_{n=1}^N\bl{\phi}(\bl{x}_n)\bl{\phi}(\bl{x}_n)^T)
     \end{equation*}
     Hence we get
     \begin{equation*}
     \bl{w}_{ML}=(\bl{\Phi}^T\bl{\Phi})^{-1}\bl{\Phi}^T\bl{t}
     \end{equation*}
     $\Phi$ is *design matrix*.
     #+ATTR_LATEX: :mode math :environment pmatrix :math-prefix \Phi=
     | \phi_0(\bl{x}_1) | \phi_1(\bl{x}_1) | \dots  | \phi_{M-1}(\bl{x}_1) |
     | \phi_0(\bl{x}_2) | \phi_1(\bl{x}_2) | \dots  | \phi_{M-1}(\bl{x}_2) |
     | \vdots           | \vdots           | \ddots | \vdots               |
     | \phi_0(\bl{x}_N) | \phi_1(\bl{x}_N) | \dots  | \phi_{M-1}(\bl{x}_N) |

     For bias parameter $w_0$.
     $E_D(\bl{w})=\frac{1}{2}\displaystyle\sum_{n=1}^N 
     \{t_n-w_0-\displaystyle\sum_{j=1}^{M-1}w_j\phi_j(\bl{x}_n)\}^2$. Hence
     $w_0=\bar{t}-\displaystyle\sum_{j=1}^{M-1}w_j\bar{\phi_j}$,
     $\bar{t}=\frac{1}{N}\displaystyle\sum_{n=1}^Nt_n$,
     $\bar{\phi_j}=\frac{1}{N}\displaystyle\sum_{n=1}^N\phi_j(\bl{x}_n)$.

     $frac{N}{2\beta}=E_D(\bl{w})$. $\frac{1}{\beta_{ML}}=
     \frac{1}{N}\displaystyle\sum_{n=1}^N\left\{t_n-\bl{w}^T_{ML}
     \bl{\phi}(\bl{x}_n)\right\}^2$
**** Least-squares approach
     + Problem
       - Each class $\mathcal{C}_k$ is described by its own linear model 
         $y_k(\bl{x})=\bl{w}_k^T\bl{x}+w_{k0}$
       - group together: $y(\bl{x})=\widetilde{\bl{W}}^T\tilde{\bl{x}}$,
         $\tilde{\bl{w}}_k=(w_{k0},\bl{w}_k^T)^T$, $\tilde{\bl{x}}=(1,\bl{x}^T)^T$
     + Learning
       - minimizing SSE function sum-of-squares
         $SSE=\displaystyle\sum_{i=1}^n(y_i-f(x_i))^2$
         $E_D(\widetilde{\bl{W}})=1/2\text{Tr}\{(\bl{\widetilde{X}\widetilde{W}-T})^T 
         (\bl{\widetilde{X}\widetilde{W}-T})\}$

         $\bl{\widetilde{W}}=(\bl{\widetilde{X}}^T\bl{\widetilde{X}})^{-1}\bl{\widetilde{X}}^T\bl{T}$
**** fisher's linear discriminant

     \includegraphics[width=100mm]{Fisher}

     from the view of dimensionality reduction
     $y\ge -w_0$ as class $\mathcal{C}_1$

     $m_1=\frac{1}{N_1}\displaystyle\sum_{n\in\mathcal{C}_1}x_n, 
     m_2=\frac{1}{N_2}\displaystyle\sum_{n\in\mathcal{C}_2}x_n
     \xrightarrow{y=\bl{w}^T\bl{x}} m_2-m_1=\bl{w}^T(\bl{m}_2-\bl{m}_1)$
**** the perceptron algorithm of rosenblatt
** probalibilistic generative models
   A probabilistic view of classification from simple assumptions about the
   distribution of the data

   \begin{align*}
   p(\mathcal{C}_1|\bl{x})&=\frac{p(\bl{x}|\mathcal{C}_1)p(\mathcal{C}_1)}
   {p(\bl{x}|\mathcal{C}_1)p(\mathcal{C}_1)+p(\bl{x}|\mathcal{C}_2)p(\mathcal{C}_2)}\\
   &=\frac{1}{1+\exp(-a)}=\sigma(a)
   \end{align*}
   where 
   \begin{equation*}
   a=\ln\frac{p(\bl{x}|\mathcal{C}_1)p(\mathcal{C}_1)}
   {p(\bl{x}|\mathcal{C}_2)p(\mathcal{C}_2)}
   \end{equation*}
   and $\sigma(a)$ is the *logistic sigmoid* function defined by
   \begin{equation*}
   \sigma(a)=\frac{1}{1+\exp(-a)}
   \end{equation*}
   and $\sigma(-a)=1-\sigma(a)$, its inverse is *logit* function
   \begin{equation*}
   a=\ln(\frac{\sigma}{1-\sigma})
   \end{equation*}

   For case of $K > 2$ classes, we have the following *multi-class generalization*
   \begin{equation*}
   p(\mathcal{C}_k|\bl{x})=\frac{p(\bl{x}|\mathcal{C}_k)p(\mathcal{C}_k)}
   {\sum_jp(\bl{x}|\mathcal{C}_j)p(\mathcal{C}_j)}=\frac{\exp(a_k)}{\sum_j\exp(a_j)},
   a_k=\ln\left[p(\bl{x}|\mathcal{C}_k)p(\mathcal{C}_k)\right]
   \end{equation*}
   The *normalized exponential* is known as the *softmax function* as it represents
   a /smoothed version of the max function/
   \begin{equation*}
   \text{if } a_k\ll a_j,\forall j\neq k,\text{then } p(\mathcal{C}_k|\bl{x})\approx 1,
   p(\mathcal{C}_j|\bl{x})\approx 0
   \end{equation*}

   For *continuous inputs*, assume
   \begin{equation*}
   p(\bl{x}|\mathcal{C}_k)=\frac{1}{(2\pi)^{D/2}}\frac{1}
   {\abs{\bl{\Sigma}}^{1/2}}\exp\left\{-\frac{1}{2}(\bl{x}-\bl{\mu}_k)^T
   \bl{\Sigma^{-1}}(\bl{x}-\bl{\mu}_k)\right\}
   \end{equation*}
   1. 2 classes
      \begin{align*}
      p(\mathcal{C}_1|\bl{x})&=\sigma(\bl{w}^T\bl{x}+w_0)\\
      \bl{w}&=\bl{\Sigma}^{-1}(\bl{\mu}_1-\bl{\mu}_2)\\
      w_0&=-\frac{1}{2}\bl{\mu}_1^T\bl{\Sigma}^{-1}\bl{\mu}_1+
      \frac{1}{2}\bl{\mu}_2^T\bl{\Sigma}^{-1}\bl{\mu}_2+\ln\frac{p(\mathcal{C}_1)}
      {p(\mathcal{C}_2)}\\
      \end{align*}
   2. K classes
      \begin{align*}
      a_k(\bl{x})&=\bl{w}_k^T\bl{x}+w_{k0}\\
      \bl{w}_k&=\bl{\Sigma}^{-1}\bl{\mu}_k\\
      w_{k0}&=-\frac{1}{2}\bl{\mu}_k^T\bl{\Sigma}^{-1}\bl{\mu}_k+\ln p(\mathcal{C}_k)
      \end{align*}
** probabilistic discriminative models
** Boosting
   Originally designed for classification problems.

   Motivation: a procedure that combines the outputs of many "weak" classifiers
   to produce a strong/accurate classifier

   
*** AdaBoost
    \includegraphics[width=100mm]{Boosting}
* unsupervised learning - clustering em and PCA
** K-means clustering
   * Distortion measure
     $J=\displaystyle\sum_{n=1}^N \displaystyle\sum_{k=1}^Kr_{nk}
     \norm{\bl{x}_n-\bl{\mu}_k}^2$
** Mixtures of Gaussians
   + Definition: 
     \begin{equation*}
     p(\bl{x})=\displaystyle\sum_{k=1}^K\pi_k\mathcal{N}
     (\bl{x}|\bl{\mu}_k,\bl{\Sigma}_k)\quad \displaystyle\sum_{k=1}^k\pi_k=1
     \quad 0\le\pi_k\le1
     \end{equation*}
   + introduce a K-dimensional binary random variable $\bl{z}=(z_1,\dots,z_k)^T$
     \begin{equation*}
     z_k\in\{0,1\}\quad \displaystyle\sum_kz_k=1\quad p(z_k=1)=\pi_k
     \end{equation*}

     Hence $p(\bl{z})
     =\displaystyle\prod_{k=1}^K\pi_k^{z_k}$, $\bz$ is *latent variable* (inferred
     from other observed variables)

     If $p(\bl{x}|z_k=1)=\mathcal{N}(\bl{x}|\bl{\mu}_k,\bl{\Sigma})$, then
     $p(\bl{x}|\bl{z})=\displaystyle\prod_{k=1}^K\mathcal{N}(\bl{x}|\bl{\mu}_k,
     \bl{\Sigma}_k)^{z_k}$
   + *equivalent formulation* of the Gaussian mixture.
     \begin{align*}
     \Aboxed{
     p(\bl{x})&=\displaystyle\sum_{\bl{z}}p(\bl{x}|\bl{z})p(\bl{z})
     =\displaystyle\sum_{\bl{z}}\displaystyle\prod_{k=1}^K
     \mathcal{N}(\bl{x}|\bl{\mu}_k,\bl{\Sigma}_k)^{z_k}}\\
     &=\displaystyle\sum_{j=1}^K\displaystyle\prod_{k=1}^K\mathcal{N}(\bl{x}|\bl{\mu}_k,
     \bl{\Sigma}_k)^{I_{kj}}\quad I_{kj}=
     \begin{cases}
     1&\text{if } k=j\\
     0&\text{otherwise}
     \end{cases}\\
     &=\displaystyle\sum_{j=1}^K\pi_j\mathcal{N}(\bl{x}|\bl{\mu}_j,\bl{\Sigma}_j)
     \end{align*}

     responsibility:
     \begin{equation*}
     \gamma(z_k)=p(z_k=1|\bx)=\frac{p(z_k=1)p(\bx|z_k=1)}{\dissum_{j=1}^Kp(z_j=1)p(\bx|z_j=1)}
     =\frac{ \pi_k\caln(\bx|\bmu_k,\bSigma)}{\dissum_{j=1}^K\pi_j\caln(\bx|\bmu_j
     \bSigma_j)}
     \end{equation*}
     \includegraphics[width=130mm]{GMM}

   *Expectation-Maximization algorithm for GMM*. 
   $p(\bX|)=\dispro p(\bx)$

   $\ln p(\bX|\pi,\bmu, \bSigma)=\dissum_{n=1}^N\ln\left\{
   \dissum_{k=1}^K\pi_k\caln(\bx_n|\bmu_k,\bSigma_k)\right\}$
   1. E step
      \begin{equation*}
      \gamma(z_{nk})=\frac{\pi_k\caln(\bx_n|\bmu_k,\bSigma_k)}
      {\dissum_j\pi_j\caln(\bx_n|\bmu_j,\bSigma_j)}
      \end{equation*}
   2. M step
      * solve $\bmu_k$
        \begin{align*}
        &\frac{\partial\ln p(\bX|\pi,\bmu,\bSigma)}{\partial\bmu_k}=0\\
        &0=-\frac{\pi_k\caln(\bx_n|\bmu_k,\bSigma_k)}
        {\dissum_j\pi_j\caln(\bx_n|\bmu_j,\bSigma_j)}\bSigma_k^{-1}(\bx_n-\bmu_k)\\
        &\bmu_k=\frac{1}{N_k}\dissum_{n=1}^N\gamma(z_{nk})\bx_n\\
        &N_k=\dissum_{n=1}^N\gamma(z_{nk})
        \end{align*}
      * solve $\bSigma_k$
        \begin{align*}
        &\frac{\partial\ln p(\bX|\pi,\bmu,\bSigma)}{\partial\bSigma_k}=0\\
        &\bSigma_k=\frac{1}{N_k}\dissum_{n=1}^N\gamma(z_{nk})(\bx_n-\bmu_k)(\bx_n-\bmu_k)^T
        \end{align*}

        
   *EM for Gaussian Mixtures*
   1. initialize the means $\bmu_k$, covariances $\bSigma_k$ and mixing
      coefficients $\pi_k$
   2. E step
   3. M step
   4. evaluate the log likelihood
      \begin{equation*}
      \ln p(\bX|\pi,\bmu, \bSigma)=\dissum_{n=1}^N\ln\left\{
      \dissum_{k=1}^K\pi_k\caln(\bx_n|\bmu_k,\bSigma_k)\right\}
      \end{equation*}
      and check for convergence of either the parameters or the log likelihood.
      If the convergence criterion is not satisfied return to step 2
** An alternative view of EM
*** the general EM algorithm
    The log likelihood of a discrete latent variables model
    \begin{equation*}
    \ln p(\bX|\theta)=\ln\lb\dissum_{\bZ} p(\bX,\bZ|\btheta)\rb
    \end{equation*}


    /the goal of EM algorithm is to find maximum likelihood solution for models
    having latent variables/ 


    For the complete data set $\lb\bX,\bZ\rb$, the likelihood function
    \begin{equation*}
    \ln p(\bX|\btheta)\Longrightarrow \ln p(\bX,\bZ|\btheta)
    \end{equation*}


    For the incomplete data set $\lb\bX\rb$, we adopt the following steps to
    find maximum likelihood solution
    \begin{tikzpicture}[node distance=2.5cm]
    \tikzstyle{arrow}=[->,thick];
    \node (1) [] {$\btheta^\text{old}$};
    \node (2) [below left of=1] {$p(\bZ|\bX,\btheta^\text{old})$};
    \node (3) [below right of=2] {$\E_{\bZ}[\ln p(\bX,\bZ|\btheta)]=\displaystyle\sum_{\bZ}
    p(\bZ|\bX,\btheta^\text{old})\ln p(\bX,\bZ|\btheta)\Q (\btheta,\btheta^\text{old})$};
    \node (4) [below right of=1] {$\btheta^\text{new}=\text{arg} \max_{\btheta}\calq(\btheta,\btheta^\text{old})$};
    \draw [arrow] (1) -- (2);
    \draw [arrow] (2) -- (3);
    \draw [arrow] (3) -- (4);
    \draw [arrow] (4) -- (1);
    \end{tikzpicture}
* reinforcement learning

* wef
** wfe
   K-means
